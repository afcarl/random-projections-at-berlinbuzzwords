0. Restructure code and add testing
1. Add noise to queries and check the sensitivity of indexing structures to noise
2. Introduce reverse rotation and remove the memory in IndexBuilder.buildWithSVDAndRandomRotation
3. Check that the Hadamard transformation works for features whose size is not power of 2
4. Check if introducing a permutation of the hadamard matrix makes a difference (it probably should)
5. Introduce a single queue (see branch) for scoring the points
6. Pre-slit the data into multiple subspaces and compute the SVD subspace dimension
7. Compare with PCA tree at various levels of number of data points and so on
8. Introduce dependent trees ("introduce information about "close points" from the previous (m - 1) trees
into the m-th tree, remove the subspace of the "merged points" -- trees that take longer to build
but a more accurate as a way to reduce the memory usage)
9. Introduce a more generic SignatureFit where there are multiple ways to compute point signagures
(for example, we can have a few subspaces and a single signature per subspace)
10. Add testing infrastructure
11. Factor out serialization core into a new project
12. Move the Online SVD code into an actor
13. Load data files asyncronously
14. Speedup code when using storage as bytes not as doubles
15. add versioning and checksums to the serialization
16. remove big array used during querying
17. apply a random permutation to the hadamard matrix
18. Replace the StringStore
19. Add specialied point ids stores (e.g. for longs/integers, consequtive etc.)
20. add a parameter to the search: how many points to touch in all trees
21. add a warm up method which will cause JIT of the relevant parts
22. add a parameter how many trees to load
23. add a parameter to create multipe trees simultaneously
24. add test files for the special cases (e.g. dataset with one huge cluster, too many points are too close, etc.)
    (cases which will make it hard to run without preprocessing)
25. Move the async file read/write to futures or another more sane approach
26. Add code to find "heavy" features (since they break the random proj. method) and also "heavy subspaces"
    and apply RandomProj to the headvy subspaces (this is a small number of features that account
        for large percentage of the mass of the point)
27. Drop the requirement for cosine and switch to dot products